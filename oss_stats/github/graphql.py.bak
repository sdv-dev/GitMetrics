import time
from functools import lru_cache
from datetime import date, datetime
from operator import itemgetter as item

import pandas as pd
from github import Github, RateLimitExceededException
from tqdm.auto import tqdm, trange
import requests
import json

tqdm.pandas()


GRAPHQL_URL = 'https://api.github.com/graphql'

REPO_ENVELOPE = """
{{
    repository(owner: "{owner}", name: "{name}") {{
        {query_body}
    }}
}}
"""
STARGAZER_COUNT = 'stargazerCount'
STARGAZERS = """
stargazers(first: 100{end_cursor}) {{
    pageInfo {{
        endCursor
        hasNextPage
        hasPreviousPage
        startCursor
    }}
    totalCount
    edges {{
        node {{
            login
            name
            email
            websiteUrl
            company
            location
            twitterUsername
            createdAt
            updatedAt
            bio
        }}
        starredAt
    }}
}}
"""

ISSUE_COUNT = """
issues {{
    totalCount
}}
"""
ISSUES = """
issues(first: 100{end_cursor}) {{
    pageInfo {{
        endCursor
        hasNextPage
        hasPreviousPage
        startCursor
    }}
    totalCount
    edges {{
        node {{
            author {{
                login
            }}
            number
            createdAt
            closedAt
            state
            title
        }}
    }}
}}
"""


# UNUSED
USER_SUBCOLLECTIONS = """
            repositories {{
                totalCount
            }}
            gists {{
                totalCount
            }}
            followers {{
                totalCount
            }}
            following {{
                totalCount
            }}
            starredRepositories {{
                totalCount
            }}
"""


def get(obj, key):
    for level in key.split('.'):
        obj = obj[level]

    return obj


class GQLClient:

    def __init__(self, token, verbose=False):
        self.verbose = verbose
        self.token = token
        self.headers = {'Authorization': f'token {token}'}

    def run_query(self, query, query_maker=None, prefix=None, verbose=None, **kwargs):
        if query_maker:
            query = query_maker(query, **kwargs)
        elif kwargs:
            query = query.format(**kwargs)

        if verbose is None:
            verbose = self.verbose

        if verbose:
            print(query)

        response = requests.post(
            GRAPHQL_URL,
            json={'query': query},
            headers=self.headers
        )

        if response.status_code == 200:
            response = response.json()
            if verbose:
                print(json.dumps(response, indent=4))

            if prefix:
                return get(response, prefix)

            return response
        else:
            raise Exception(f'Query fail ({response.status_code}): {response.content}')

    def paginate_collection(self, query, prefix, total, query_maker=None,
                            collection_name=None, item_parser=None, pbar=None, **kwargs):
        response = self.run_query(query, query_maker, prefix, end_cursor='', **kwargs)
        if isinstance(total, str):
            total = get(response, total)

        data = []
        if pbar is None:
            _pbar = tqdm(total=total)
        else:
            _pbar = pbar

        while True:
            if collection_name:
                collection = response[collection_name]
            else:
                collection = response

            page_info = collection['pageInfo']
            has_next_page = page_info['hasNextPage']
            end_cursor = f', after: "{page_info["endCursor"]}"'

            for item in collection['edges']:
                data.append(item_parser(item))
                _pbar.update(1)

            if not has_next_page:
                break

            response = self.run_query(query, query_maker, prefix,
                                      end_cursor=end_cursor, **kwargs)

        if pbar is None:
            _pbar.close()

        return pd.DataFrame(data)


class RepoClient(GQLClient):

    def __init__(self, token, repo, verbose=False):
        owner, name = repo.split('/')
        self.owner = owner
        self.name = name
        self.repo = repo
        super().__init__(token, verbose)

    @staticmethod
    def _indent_query(query_body, **kwargs):
        if '\n' in query_body:
            query_lines = query_body.split('\n')
            indented = [
                ' ' * 8 + line
                for line in query_lines[2:]
                if line
            ]
            query_body = '\n'.join(query_lines[1:2] + indented)

        return query_body.format(**kwargs)

    def make_query(self, query_body, **kwargs):
        query_body = self._indent_query(query_body, **kwargs)
        return REPO_ENVELOPE.format(
            owner=self.owner,
            name=self.name,
            query_body=query_body
        )[1:-1]

    def get_stargazer_count(self):
        query = self.make_query(STARGAZER_COUNT)
        response = self.run_query(query, prefix='data.repository')
        return get(response, STARGAZER_COUNT)

    @staticmethod
    def _stargazer_parser(stargazer):
        node = stargazer['node']
        return {
            'user': node['login'],
            'starred_at': stargazer['starredAt'],
            'name': node['name'],
            'email': node['email'],
            'blog': node['websiteUrl'],
            'company': node['company'],
            'location': node['location'],
            'twitter': node['twitterUsername'],
            'user_created_at': node['createdAt'],
            'user_updated_at': node['updatedAt'],
            'bio': node['bio'],
        }

    def get_stargazers(self):
        return self.paginate_collection(
            query=STARGAZERS,
            prefix='data.repository',
            total='stargazers.totalCount',
            collection_name='stargazers',
            item_parser=self._stargazer_parser,
            query_maker=self.make_query
        )

    def get_issue_count(self):
        query = self.make_query(ISSUE_COUNT)
        response = self.run_query(query, prefix='data.repository')
        return get(response, 'issues.totalCount')

    @staticmethod
    def _issue_parser(issue):
        node = issue['node']
        author = node['author'] or {}
        return {
            'user': author.get('login'),
            'created_at': node['createdAt'],
            'closed_at': node['closedAt'],
            'number': node['number'],
            'state': node['state'],
            'title': node['title'],
        }

    def get_issues(self):
        return self.paginate_collection(
            query=ISSUES,
            prefix='data.repository',
            total='issues.totalCount',
            collection_name='issues',
            item_parser=self._issue_parser,
            query_maker=self.make_query
        )


USERS = """
{{
    search(query: "{usernames}", type: USER, first: 100{end_cursor}) {{
        pageInfo {{
            endCursor
            hasNextPage
            hasPreviousPage
            startCursor
        }}
        userCount
        edges {{
            node {{
                ... on User {{
                    login
                    name
                    email
                    websiteUrl
                    company
                    location
                    twitterUsername
                    createdAt
                    updatedAt
                    bio
                }}
            }}
        }}
    }}
}}
"""

class UsersClient(GQLClient):

    def user_parser(self, user):
        node = user['node']
        return {
            'user': node['login'],
            'name': node['name'],
            'email': node['email'],
            'blog': node['websiteUrl'],
            'company': node['company'],
            'location': node['location'],
            'twitter': node['twitterUsername'],
            'user_created_at': node['createdAt'],
            'user_updated_at': node['updatedAt'],
            'bio': node['bio'],
        }

    def get_users(self, usernames):
        out = pd.DataFrame()
        total = len(usernames)
        pbar = tqdm(total=total)
        for index in range(0, total, 100):
            chunk = usernames[index:index + 100]
            chunk_users = self.paginate_collection(
                query=USERS,
                prefix='data.search',
                total='userCount',
                item_parser=self.user_parser,
                pbar=pbar,
                usernames=' '.join(f'user:{user}' for user in chunk)
            )
            out = out.append(chunk_users, ignore_index=True)

        pbar.close()

        return out.sort_values('user', ignore_index=True)


def get_github_stats(token, repos, name):
    issues = pd.DataFrame()
    stargazers = pd.DataFrame()

    print('Getting issues and stargazers')
    for repo in repos:
        rc = RepoClient(token, repo)
        issues = issues.append(rc.get_issues(), ignore_index=True)
        stargazers = stargazers.append(rc.get_stargazers(), ignore_index=True)

    print('Getting users')
    uc = UsersClient(token)
    unique_users = issues.user.dropna().unique().tolist()
    users = uc.get_users(unique_users)

    issues = issues.merge(users, how='left', on='user')

    create_excel(name, issues, users, stargazers)
